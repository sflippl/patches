{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first implementation of contrastive predictive coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotnine as gg\n",
    "import lettertask\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data: compositional binary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbm = lettertask.data.CompositionalBinaryModel(\n",
    "    width=[2],\n",
    "    change_probability=[0.05],\n",
    "    samples=10000,\n",
    "    seed=1001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositionalBinaryData(torch.utils.data.Dataset):\n",
    "    \"\"\"Provides video data following the Pytorch Dataset framework.\n",
    "    \"\"\"\n",
    "    def __init__(self, cbm, contrastive_samples=1, use_seed=True,\n",
    "                 predictions=range(1, 2)):\n",
    "        self.cbm = cbm\n",
    "        self.contrastive_samples = contrastive_samples\n",
    "        self.predictions = predictions\n",
    "        if use_seed:\n",
    "            self.random_state = cbm.random_state\n",
    "        else:\n",
    "            self.random_state = np.random.RandomState()\n",
    "\n",
    "    def sample(self, samples=0):\n",
    "        \"\"\"Continue sampling the compositional binary data.\n",
    "        \"\"\"\n",
    "        self.cbm.sample(samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        arrs = []\n",
    "        predictions = []\n",
    "        contrastive_samples = []\n",
    "        for __ in range(self.contrastive_samples):\n",
    "            contrastive_samples.append([])\n",
    "        contrastive_idxs = torch.randint(0, len(self), (self.contrastive_samples, ))\n",
    "        for atom in self.cbm.atoms:\n",
    "            arr = np.zeros(shape=(1, atom.width))\n",
    "            arr[0, atom.locations[idx][0]] = atom.values[idx]\n",
    "            arrs.append(arr)\n",
    "            prediction = np.zeros(shape=(len(self.predictions), atom.width))\n",
    "            for i, pred_idx in enumerate(self.predictions):\n",
    "                prediction[i, atom.locations[pred_idx][0]] = atom.values[pred_idx]\n",
    "            predictions.append(prediction)\n",
    "            for c_idx, contrastive_sample in zip(contrastive_idxs,\n",
    "                                                 contrastive_samples):\n",
    "                arr = np.zeros(shape=(1, atom.width))\n",
    "                arr[0, atom.locations[c_idx][0]] = atom.values[c_idx]\n",
    "                contrastive_sample.append(arr)\n",
    "        arr = np.concatenate(arrs, axis=1)\n",
    "        contrast = np.concatenate([\n",
    "            np.concatenate(c_arrs, axis=1) for c_arrs in contrastive_samples\n",
    "        ], axis=0)\n",
    "        predicted = np.concatenate(predictions, axis=1)\n",
    "        return {'sample': torch.tensor(arr.astype('float32'), requires_grad=True),\n",
    "                'predicted': torch.tensor(predicted.astype('float32'), requires_grad=True),\n",
    "                'contrast': torch.tensor(contrast.astype('float32'), requires_grad=True)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cbm.atoms[0].locations) - max(self.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbd = CompositionalBinaryData(cbm, contrastive_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastivePredictiveNet(nn.Module):\n",
    "    def __init__(self, timesteps=10):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(2, 1, bias=False)\n",
    "        #self.predictor = nn.Linear(1, timesteps, bias=False)\n",
    "        self.predictor = torch.tensor(-1., dtype=torch.float, requires_grad=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = {\n",
    "            'sample': self.encoder(x['sample']),\n",
    "            'contrast': self.encoder(x['contrast']),\n",
    "            'predicted': self.encoder(x['predicted'])\n",
    "        }\n",
    "        encoded['prediction'] = self.predictor(encoded['sample'])\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(x, y):\n",
    "    return torch.data(x[:,0], y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crit(predictions):\n",
    "    pred_loss = torch.exp(criterion(predictions['sample'],\n",
    "                                    predictions['predicted']))\n",
    "    contrast_loss = pred_loss + torch.sum(\n",
    "        torch.exp(\n",
    "            predictions['contrast']*predictions['sample']\n",
    "        )\n",
    "    )\n",
    "    return -torch.log(pred_loss)+torch.log(contrast_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpn = ContrastivePredictiveNet(timesteps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1., requires_grad=True)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpn.predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params = [cpn.predictor], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cpn(cbd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 0.838\n",
      "[1,  1000] loss: 0.876\n",
      "[1,  1500] loss: 0.819\n",
      "[1,  2000] loss: 1.120\n",
      "[1,  2500] loss: 0.696\n",
      "[1,  3000] loss: 0.824\n",
      "[1,  3500] loss: 1.002\n",
      "[1,  4000] loss: 1.116\n",
      "[1,  4500] loss: 0.998\n",
      "[1,  5000] loss: 0.933\n",
      "[1,  5500] loss: 1.044\n",
      "[1,  6000] loss: 0.768\n",
      "[1,  6500] loss: 0.899\n",
      "[1,  7000] loss: 0.689\n",
      "[1,  7500] loss: 0.788\n",
      "[1,  8000] loss: 1.018\n",
      "[1,  8500] loss: 0.847\n",
      "[1,  9000] loss: 0.869\n",
      "[1,  9500] loss: 1.048\n",
      "[1, 10000] loss: 1.099\n",
      "[2,   500] loss: 0.813\n",
      "[2,  1000] loss: 0.839\n",
      "[2,  1500] loss: 0.809\n",
      "[2,  2000] loss: 1.176\n",
      "[2,  2500] loss: 0.735\n",
      "[2,  3000] loss: 0.807\n",
      "[2,  3500] loss: 0.973\n",
      "[2,  4000] loss: 1.096\n",
      "[2,  4500] loss: 0.944\n",
      "[2,  5000] loss: 0.972\n",
      "[2,  5500] loss: 1.014\n",
      "[2,  6000] loss: 0.814\n",
      "[2,  6500] loss: 0.877\n",
      "[2,  7000] loss: 0.733\n",
      "[2,  7500] loss: 0.796\n",
      "[2,  8000] loss: 1.009\n",
      "[2,  8500] loss: 0.876\n",
      "[2,  9000] loss: 0.888\n",
      "[2,  9500] loss: 0.973\n",
      "[2, 10000] loss: 1.048\n",
      "[3,   500] loss: 0.783\n",
      "[3,  1000] loss: 0.873\n",
      "[3,  1500] loss: 0.763\n",
      "[3,  2000] loss: 1.138\n",
      "[3,  2500] loss: 0.712\n",
      "[3,  3000] loss: 0.793\n",
      "[3,  3500] loss: 0.936\n",
      "[3,  4000] loss: 1.124\n",
      "[3,  4500] loss: 0.985\n",
      "[3,  5000] loss: 0.944\n",
      "[3,  5500] loss: 1.062\n",
      "[3,  6000] loss: 0.750\n",
      "[3,  6500] loss: 0.892\n",
      "[3,  7000] loss: 0.729\n",
      "[3,  7500] loss: 0.890\n",
      "[3,  8000] loss: 0.991\n",
      "[3,  8500] loss: 0.837\n",
      "[3,  9000] loss: 0.857\n",
      "[3,  9500] loss: 1.001\n",
      "[3, 10000] loss: 1.036\n",
      "[4,   500] loss: 0.813\n",
      "[4,  1000] loss: 0.862\n",
      "[4,  1500] loss: 0.831\n",
      "[4,  2000] loss: 1.160\n",
      "[4,  2500] loss: 0.699\n",
      "[4,  3000] loss: 0.764\n",
      "[4,  3500] loss: 0.928\n",
      "[4,  4000] loss: 1.137\n",
      "[4,  4500] loss: 0.944\n",
      "[4,  5000] loss: 0.943\n",
      "[4,  5500] loss: 1.040\n",
      "[4,  6000] loss: 0.757\n",
      "[4,  6500] loss: 0.894\n",
      "[4,  7000] loss: 0.717\n",
      "[4,  7500] loss: 0.787\n",
      "[4,  8000] loss: 1.022\n",
      "[4,  8500] loss: 0.822\n",
      "[4,  9000] loss: 0.852\n",
      "[4,  9500] loss: 1.030\n",
      "[4, 10000] loss: 1.072\n",
      "[5,   500] loss: 0.849\n",
      "[5,  1000] loss: 0.854\n",
      "[5,  1500] loss: 0.846\n",
      "[5,  2000] loss: 1.181\n",
      "[5,  2500] loss: 0.693\n",
      "[5,  3000] loss: 0.797\n",
      "[5,  3500] loss: 1.001\n",
      "[5,  4000] loss: 1.129\n",
      "[5,  4500] loss: 1.000\n",
      "[5,  5000] loss: 0.910\n",
      "[5,  5500] loss: 1.070\n",
      "[5,  6000] loss: 0.834\n",
      "[5,  6500] loss: 0.858\n",
      "[5,  7000] loss: 0.724\n",
      "[5,  7500] loss: 0.821\n",
      "[5,  8000] loss: 1.031\n",
      "[5,  8500] loss: 0.881\n",
      "[5,  9000] loss: 0.901\n",
      "[5,  9500] loss: 1.008\n",
      "[5, 10000] loss: 1.059\n",
      "[6,   500] loss: 0.835\n",
      "[6,  1000] loss: 0.876\n",
      "[6,  1500] loss: 0.839\n",
      "[6,  2000] loss: 1.143\n",
      "[6,  2500] loss: 0.693\n",
      "[6,  3000] loss: 0.826\n",
      "[6,  3500] loss: 0.966\n",
      "[6,  4000] loss: 1.143\n",
      "[6,  4500] loss: 0.964\n",
      "[6,  5000] loss: 0.930\n",
      "[6,  5500] loss: 1.066\n",
      "[6,  6000] loss: 0.837\n",
      "[6,  6500] loss: 0.848\n",
      "[6,  7000] loss: 0.722\n",
      "[6,  7500] loss: 0.819\n",
      "[6,  8000] loss: 1.001\n",
      "[6,  8500] loss: 0.851\n",
      "[6,  9000] loss: 0.878\n",
      "[6,  9500] loss: 1.014\n",
      "[6, 10000] loss: 1.078\n",
      "[7,   500] loss: 0.831\n",
      "[7,  1000] loss: 0.912\n",
      "[7,  1500] loss: 0.809\n",
      "[7,  2000] loss: 1.081\n",
      "[7,  2500] loss: 0.657\n",
      "[7,  3000] loss: 0.821\n",
      "[7,  3500] loss: 1.027\n",
      "[7,  4000] loss: 1.088\n",
      "[7,  4500] loss: 0.984\n",
      "[7,  5000] loss: 0.926\n",
      "[7,  5500] loss: 1.022\n",
      "[7,  6000] loss: 0.785\n",
      "[7,  6500] loss: 0.886\n",
      "[7,  7000] loss: 0.717\n",
      "[7,  7500] loss: 0.777\n",
      "[7,  8000] loss: 0.991\n",
      "[7,  8500] loss: 0.866\n",
      "[7,  9000] loss: 0.862\n",
      "[7,  9500] loss: 1.030\n",
      "[7, 10000] loss: 1.091\n",
      "[8,   500] loss: 0.805\n",
      "[8,  1000] loss: 0.862\n",
      "[8,  1500] loss: 0.806\n",
      "[8,  2000] loss: 1.138\n",
      "[8,  2500] loss: 0.704\n",
      "[8,  3000] loss: 0.794\n",
      "[8,  3500] loss: 0.973\n",
      "[8,  4000] loss: 1.124\n",
      "[8,  4500] loss: 0.960\n",
      "[8,  5000] loss: 0.875\n",
      "[8,  5500] loss: 1.011\n",
      "[8,  6000] loss: 0.779\n",
      "[8,  6500] loss: 0.891\n",
      "[8,  7000] loss: 0.757\n",
      "[8,  7500] loss: 0.847\n",
      "[8,  8000] loss: 1.016\n",
      "[8,  8500] loss: 0.832\n",
      "[8,  9000] loss: 0.858\n",
      "[8,  9500] loss: 1.063\n",
      "[8, 10000] loss: 1.018\n",
      "[9,   500] loss: 0.823\n",
      "[9,  1000] loss: 0.800\n",
      "[9,  1500] loss: 0.836\n",
      "[9,  2000] loss: 1.099\n",
      "[9,  2500] loss: 0.726\n",
      "[9,  3000] loss: 0.806\n",
      "[9,  3500] loss: 0.984\n",
      "[9,  4000] loss: 1.104\n",
      "[9,  4500] loss: 0.945\n",
      "[9,  5000] loss: 1.000\n",
      "[9,  5500] loss: 1.076\n",
      "[9,  6000] loss: 0.816\n",
      "[9,  6500] loss: 0.849\n",
      "[9,  7000] loss: 0.756\n",
      "[9,  7500] loss: 0.836\n",
      "[9,  8000] loss: 0.997\n",
      "[9,  8500] loss: 0.842\n",
      "[9,  9000] loss: 0.837\n",
      "[9,  9500] loss: 0.990\n",
      "[9, 10000] loss: 1.021\n",
      "[10,   500] loss: 0.837\n",
      "[10,  1000] loss: 0.923\n",
      "[10,  1500] loss: 0.828\n",
      "[10,  2000] loss: 1.115\n",
      "[10,  2500] loss: 0.690\n",
      "[10,  3000] loss: 0.773\n",
      "[10,  3500] loss: 0.999\n",
      "[10,  4000] loss: 1.097\n",
      "[10,  4500] loss: 0.994\n",
      "[10,  5000] loss: 0.927\n",
      "[10,  5500] loss: 1.088\n",
      "[10,  6000] loss: 0.774\n",
      "[10,  6500] loss: 0.888\n",
      "[10,  7000] loss: 0.747\n",
      "[10,  7500] loss: 0.816\n",
      "[10,  8000] loss: 1.031\n",
      "[10,  8500] loss: 0.808\n",
      "[10,  9000] loss: 0.901\n",
      "[10,  9500] loss: 1.001\n",
      "[10, 10000] loss: 1.059\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(cbd):\n",
    "        inputs = data\n",
    "        optimizer.zero_grad()\n",
    "        predictions = cpn(inputs)\n",
    "        loss = crit(predictions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 500 == 499:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 500))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1., requires_grad=True)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpn.predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample': tensor([[0.1383]], grad_fn=<MmBackward>),\n",
       " 'predicted': tensor([[0.0611]], grad_fn=<MmBackward>),\n",
       " 'contrast': tensor([[ 0.0414],\n",
       "         [-0.0790],\n",
       "         [-0.0790],\n",
       "         [ 0.0880],\n",
       "         [-0.0611],\n",
       "         [-0.0880],\n",
       "         [ 0.0889],\n",
       "         [ 0.1649],\n",
       "         [ 0.0790],\n",
       "         [ 0.1383],\n",
       "         [ 0.0790],\n",
       "         [ 0.1649],\n",
       "         [-0.0611],\n",
       "         [-0.0790],\n",
       "         [-0.1148],\n",
       "         [ 0.1649],\n",
       "         [ 0.1383],\n",
       "         [-0.0880],\n",
       "         [ 0.0790],\n",
       "         [ 0.0414],\n",
       "         [-0.1148],\n",
       "         [-0.2104],\n",
       "         [ 0.0889],\n",
       "         [-0.0889],\n",
       "         [ 0.1148],\n",
       "         [-0.0414],\n",
       "         [-0.0611],\n",
       "         [ 0.1649],\n",
       "         [-0.1325],\n",
       "         [-0.2104],\n",
       "         [-0.0611],\n",
       "         [-0.0611],\n",
       "         [ 0.1148],\n",
       "         [-0.0889],\n",
       "         [ 0.0880],\n",
       "         [ 0.0889],\n",
       "         [-0.2104],\n",
       "         [ 0.0414],\n",
       "         [-0.1148],\n",
       "         [-0.0889],\n",
       "         [ 0.1325],\n",
       "         [ 0.0880],\n",
       "         [ 0.1325],\n",
       "         [ 0.0889],\n",
       "         [ 0.1148],\n",
       "         [-0.0790],\n",
       "         [-0.1325],\n",
       "         [-0.1148],\n",
       "         [-0.2104],\n",
       "         [-0.1383],\n",
       "         [ 0.1383],\n",
       "         [-0.0889],\n",
       "         [-0.1649],\n",
       "         [ 0.0414],\n",
       "         [-0.1148],\n",
       "         [-0.0889],\n",
       "         [-0.1148],\n",
       "         [-0.0889],\n",
       "         [-0.2104],\n",
       "         [ 0.0790],\n",
       "         [ 0.0790],\n",
       "         [-0.1383],\n",
       "         [ 0.1383],\n",
       "         [-0.2104],\n",
       "         [ 0.1649],\n",
       "         [ 0.1148],\n",
       "         [ 0.0880],\n",
       "         [ 0.1649],\n",
       "         [-0.2104],\n",
       "         [ 0.0880],\n",
       "         [ 0.1325],\n",
       "         [-0.1383],\n",
       "         [ 0.1148],\n",
       "         [ 0.2104],\n",
       "         [-0.0611],\n",
       "         [-0.1649],\n",
       "         [-0.0880],\n",
       "         [ 0.0611],\n",
       "         [ 0.1649],\n",
       "         [ 0.0414],\n",
       "         [ 0.0414],\n",
       "         [-0.1383],\n",
       "         [-0.0790],\n",
       "         [ 0.2104],\n",
       "         [-0.0611],\n",
       "         [-0.0889],\n",
       "         [-0.1325],\n",
       "         [ 0.0790],\n",
       "         [ 0.1325],\n",
       "         [ 0.1325],\n",
       "         [ 0.0880],\n",
       "         [ 0.2104],\n",
       "         [-0.2104],\n",
       "         [ 0.1325],\n",
       "         [-0.2104],\n",
       "         [-0.0889],\n",
       "         [-0.0790],\n",
       "         [ 0.1148],\n",
       "         [ 0.1148],\n",
       "         [ 0.0611]], grad_fn=<MmBackward>),\n",
       " 'prediction': tensor([[-0.1090]], grad_fn=<TransposeBackward0>)}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
