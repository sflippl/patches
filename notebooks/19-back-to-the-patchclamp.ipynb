{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to the patch clamp!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patches\n",
    "import lettertask as lt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The hidden markov model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lt.data.CompositionalBinaryModel(samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = data.to_array().reshape(1, *data.to_array().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_data = data.latent_array().reshape(1, *data.latent_array().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = patches.data.HiddenMarkovModel(input_data, latent_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['input'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_generator(input_features, latent_features, timesteps, intermediate_features, **kwargs):\n",
    "    encoder = nn.Sequential(\n",
    "        nn.Linear(input_features, intermediate_features),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(intermediate_features, latent_features)\n",
    "    )\n",
    "    predictor = nn.Linear(latent_features, timesteps*latent_features)\n",
    "    decoder = nn.Linear(latent_features, input_features)\n",
    "    return {\n",
    "        'encoder': encoder,\n",
    "        'predictor': predictor,\n",
    "        'decoder': decoder\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparameters = {\n",
    "    'timesteps': [1, 5, 10],\n",
    "    'intermediate_features': [1, 2, 3, 4, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "patchclamp = patches.patchclamp.PatchClamp(model_generator, model_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scr = patchclamp.get_scr(100, 1, timesteps=5, intermediate_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2706]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scr(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6143, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scr.loss(scr(dataset[0]), dataset[0], nn.MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = patchclamp.get_cc(100, 1, timesteps=5, intermediate_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_dataset = patches.data.ContrastiveDataset(input_data, contrast_type='both',\n",
    "                                                      prediction_range=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5718, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.loss(cc(contrastive_dataset[0]), contrastive_dataset[0], nn.MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(cc.parameters())[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params/np.sqrt((params**2).sum(axis=1)).reshape(params.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideals = np.diag(1/np.sqrt(np.array([100]))).repeat(np.array([100]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function save in module numpy:\n",
      "\n",
      "save(file, arr, allow_pickle=True, fix_imports=True)\n",
      "    Save an array to a binary file in NumPy ``.npy`` format.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    file : file, str, or pathlib.Path\n",
      "        File or filename to which the data is saved.  If file is a file-object,\n",
      "        then the filename is unchanged.  If file is a string or Path, a ``.npy``\n",
      "        extension will be appended to the file name if it does not already\n",
      "        have one.\n",
      "    arr : array_like\n",
      "        Array data to be saved.\n",
      "    allow_pickle : bool, optional\n",
      "        Allow saving object arrays using Python pickles. Reasons for disallowing\n",
      "        pickles include security (loading pickled data can execute arbitrary\n",
      "        code) and portability (pickled objects may not be loadable on different\n",
      "        Python installations, for example if the stored objects require libraries\n",
      "        that are not available, and not all pickled data is compatible between\n",
      "        Python 2 and Python 3).\n",
      "        Default: True\n",
      "    fix_imports : bool, optional\n",
      "        Only useful in forcing objects in object arrays on Python 3 to be\n",
      "        pickled in a Python 2 compatible way. If `fix_imports` is True, pickle\n",
      "        will try to map the new Python 3 names to the old module names used in\n",
      "        Python 2, so that the pickle data stream is readable with Python 2.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    savez : Save several arrays into a ``.npz`` archive\n",
      "    savetxt, load\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    For a description of the ``.npy`` format, see :py:mod:`numpy.lib.format`.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from tempfile import TemporaryFile\n",
      "    >>> outfile = TemporaryFile()\n",
      "    \n",
      "    >>> x = np.arange(10)\n",
      "    >>> np.save(outfile, x)\n",
      "    \n",
      "    >>> _ = outfile.seek(0) # Only needed here to simulate closing & reopening file\n",
      "    >>> np.load(outfile)\n",
      "    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations for experiment 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studied models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = [\n",
    "    [5, 5],\n",
    "    [10, 10],\n",
    "    [50, 50],\n",
    "    [5, 10],\n",
    "    [5, 50],\n",
    "    [10, 50],\n",
    "    [100, 100],\n",
    "    [1000, 1000],\n",
    "    [5, 5, 5],\n",
    "    [10, 10, 10],\n",
    "    [50, 50, 50],\n",
    "    [5, 10, 10],\n",
    "    [5, 10, 50],\n",
    "    [50, 50, 50],\n",
    "    [100, 100, 100],\n",
    "    [100, 200, 200],\n",
    "    [5, 5, 5, 5, 5],\n",
    "    [5, 50, 50, 50, 50], \n",
    "    [100, 50, 100, 50, 100]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_probabilities = [\n",
    "    [0.05, 0.5],\n",
    "    [0.05, 0.2],\n",
    "    [0.05, 0.1],\n",
    "    [0.2, 0.5],\n",
    "    [0.05, 0.1, 0.5],\n",
    "    [0.05, 0.2, 0.5],\n",
    "    [0.05, 0.08, 0.1],\n",
    "    [0.05, 0.1, 0.2, 0.4, 0.5],\n",
    "    [0.05, 0.08, 0.1, 0.2, 0.3],\n",
    "    [0.05, 0.4, 0.45, 0.48, 0.5]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combinations = [[width, change_probability]\\\n",
    "                      for width in widths\\\n",
    "                      for change_probability in change_probabilities\\\n",
    "                      if len(width) == len(change_probability)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(seed=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = rs.choice(range(10000), size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    100, \n",
    "    1000,\n",
    "    1e4,\n",
    "    1e5,\n",
    "    5e5\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For larger models, we should implement a random search rather than a grid search, but for such a small model, it seems nice to be apply to easily marginalize different dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, however, we only use learning rate as a hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [\n",
    "    1e-6,\n",
    "    1e-5,\n",
    "    1e-4, 2e-4, 5e-4,\n",
    "    1e-3, 2e-3, 5e-3,\n",
    "    1e-2, 2e-2, 5e-2,\n",
    "    1e-1, 5e-1, 1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['SGD', 'Adam', 'Adadelta', 'Adamax']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting the data frame together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = [5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideals = np.diag(1/np.sqrt(np.array(width))).repeat(np.array(width), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CompositionalBinaryModel in module lettertask.data.atomic_model:\n",
      "\n",
      "class CompositionalBinaryModel(builtins.object)\n",
      " |  CompositionalBinaryModel(width=[100], change_probability=[0.05], samples=0, seed=None, random_state=None)\n",
      " |  \n",
      " |  The compositional binary model.\n",
      " |  \n",
      " |  This class models the compositional binary model, which consists of several\n",
      " |  atomic binary models.\n",
      " |  \n",
      " |  Args:\n",
      " |      width: How many columns should the matrix at each timestep have? (\n",
      " |          Default is 100.)\n",
      " |      change_probability: What should be the probability of the number\n",
      " |          changing in the first row? (Default is 0.05.)\n",
      " |      presamples: How many samples should be drawn initially? Further samples\n",
      " |          can always be drawn using the method 'sample'. (Default is 0.)\n",
      " |      seed: For reproducibility, you can provide a random seed.\n",
      " |  \n",
      " |  Raises:\n",
      " |      ValueError: If width is not a positive integer, change_probability is\n",
      " |          not a valid probability, presamples is negative or not an\n",
      " |          integer, or width and change_probability have unequal length.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, width=[100], change_probability=[0.05], samples=0, seed=None, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  animate(self, asp=2, fps=10, facet_labels=None, shadow=10)\n",
      " |      Animates the compositional binary model.\n",
      " |      \n",
      " |      Animations within the console do not work in arbitrary environments. The\n",
      " |      function therefore only works within IPython.\n",
      " |      \n",
      " |      Args:\n",
      " |          asp: The aspect ratio of the animation (default is 2).\n",
      " |          fps: Frames per second.\n",
      " |      \n",
      " |      Raises:\n",
      " |          NotImplementedError: If not run within IPython.\n",
      " |  \n",
      " |  animation(self, asp=2, fps=10, facet_labels=None, shadow=10, path=False)\n",
      " |      Returns an animation of the compositional binary model.\n",
      " |      \n",
      " |      Args:\n",
      " |          asp: The aspect ratio of the animation (default is 2).\n",
      " |          fps: Frames per second.\n",
      " |          path: Should the Image object or the path be returned?\n",
      " |      \n",
      " |      Returns:\n",
      " |          A PIL.Image object.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: if fancyscaffold is not installed.\n",
      " |  \n",
      " |  latent_array(self)\n",
      " |      Returns the latent values as a numpy array.\n",
      " |  \n",
      " |  prediction_scaling(self, tau)\n",
      " |      Returns the uniform prediction of a linear feature extraction.\n",
      " |      \n",
      " |      Args:\n",
      " |          tau: How many steps into the future should we predict?\n",
      " |  \n",
      " |  predictive_quality(self, tau)\n",
      " |      Returns the predictive quality of the model.\n",
      " |      \n",
      " |      Args:\n",
      " |          tau: How many steps into the future should we predict?\n",
      " |      \n",
      " |      The predictive quality provides a measure for the favorability of a\n",
      " |      certain feature under a naive linear feature extraction.\n",
      " |  \n",
      " |  sample(self, samples)\n",
      " |      Samples new events.\n",
      " |      \n",
      " |      Args:\n",
      " |          samples: Number of samples.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError:\n",
      " |              If samples are not a nonnegative integer.\n",
      " |  \n",
      " |  title(self)\n",
      " |  \n",
      " |  to_array(self)\n",
      " |      Returns the data as a numpy array.\n",
      " |  \n",
      " |  to_dataframe(self)\n",
      " |      Returns a dataframe that is compatible with the animation function in\n",
      " |      R.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lt.data.CompositionalBinaryModel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
